# VisionTechAI â€“ Vehicle vs. Animal Recognition for Autonomous Driving

> Developed as part of **AI Engineering Master â€“ Week 5**  
> This project builds and evaluates convolutional neural networks (CNNs) to distinguish between **vehicles** and **animals**, supporting safer urban mobility for autonomous driving systems.

---

## ðŸ“Œ Project Overview

VisionTechAI addresses the challenge of **real-time image recognition** for autonomous driving, with a specific focus on identifying **vehicles vs. animals**.  
The system leverages **Convolutional Neural Networks (CNNs)** trained on the **CIFAR-10 dataset**, enabling classification to support **traffic monitoring**, **wildlife protection**, and **accident prevention**.

The project experimented with **different CNN architectures and optimization strategies** to evaluate trade-offs between **accuracy**, **generalization**, and **computational efficiency**.  
This repository includes the **best-performing model (Run A â€“ Baseline CNN)** and all files needed for reproducibility.

---

## ðŸ§± Technologies and Concepts

- âœ… **Python 3.x**  
- âœ… **TensorFlow / Keras**  
- âœ… **NumPy, Matplotlib, Seaborn**  
- âœ… **CNN architectures** (convolution, pooling, dropout, dense layers)  
- âœ… **Image preprocessing and data augmentation**  
- âœ… **Optimizers**: Adam, RMSprop, Cosine Decay scheduling  
- âœ… **Early stopping & model checkpointing**  
- âœ… **Evaluation metrics**: Accuracy, Precision, Recall, F1-score  

---

## ðŸš€ Features

- ðŸ”¹ **Binary classification**: vehicles (airplane, automobile, ship, truck) vs. animals (all other CIFAR classes)  
- ðŸ”¹ Data preprocessing with **normalization and augmentation** (rotation, shifts, flips, zoom, shear)  
- ðŸ”¹ Custom CNN architecture with 3 convolutional blocks and a dense layer  
- ðŸ”¹ Experimental comparison of **optimizers (Adam, RMSprop)** and **model capacities**  
- ðŸ”¹ Training pipeline with **early stopping, checkpointing, and performance logging**  
- ðŸ”¹ Visualization of **accuracy/loss curves** and **confusion matrices**  
- ðŸ”¹ Model persistence (`.keras`, `.json`, `.csv`, `.npy`) for reproducibility  

---

## ðŸ“‚ Project Structure

- `dl-autonomous-vehicle.ipynb`: Main notebook with full implementation  
- `README.md`: Project documentation  
- `best_model_runA.keras`: Saved best-performing model (Run A)  
- `history_runA.csv`: Training history of Run A  
- `metrics_runA.json`: Evaluation metrics of Run A  
- `x_test_norm_cnn.npy, y_test_bin.npy`: Test data for reproducibility  

---

## ðŸ“Š Experimental Setup & Results

Three experimental runs were performed to test different trade-offs:

| Run | Model       | Optimizer & Schedule       | Architecture (filters, dense) | Regularization | Goal |
| --- | ----------- | -------------------------- | ----------------------------- | -------------- | ---- |
| A   | CNN base    | **Adam** (lr=1e-3)         | 32 â†’ 64 â†’ 128, Dense=256      | Dropout 0.3â€“0.5 | Baseline, establish standard performance |
| B   | CNN base    | **RMSprop + CosineDecay**  | 32 â†’ 64 â†’ 128, Dense=256      | Dropout 0.3â€“0.5 | Assess impact of RMSprop + LR scheduling |
| C   | CNN light   | **Adam** (lr=1e-3)         | 16 â†’ 32 â†’ 64, Dense=128       | Dropout 0.3     | Trade-off between accuracy and efficiency (edge deployment) |

### Results summary

---

## ðŸ“Š Key Results (Run A â€“ Baseline CNN)

| Metric      | Vehicle | Non-Vehicle | Overall |
|-------------|---------|-------------|---------|
| **Accuracy** |   â€“     |     â€“       | **96.2%** |
| **Precision** | 0.962 | 0.962       |   â€“     |
| **Recall**    | 0.942 | 0.975       |   â€“     |
| **F1-score**  | 0.952 | 0.969       |   â€“     |

âœ… Stable convergence with no signs of overfitting  
âœ… Balanced precisionâ€“recall across both classes  
âœ… ~6% of vehicles misclassified as non-vehicles, ~2% of non-vehicles misclassified as vehicles  

---

- **Run B (RMSprop + CosineDecay)**: 95.8% accuracy, slightly lower precision on vehicles but smoother validation dynamics.  
- **Run C (Light CNN)**: 95.3% accuracy, only marginally worse than Run A despite reduced capacity, showing efficiency potential.  

ðŸ‘‰ The repository includes **Run A only**, as it represents the best trade-off between accuracy and complexity.

---

## ðŸ“Ž License & Credits

This project is part of an individual portfolio developed for the **AI Engineering Master**.  
All experiments are implemented in **TensorFlow/Keras** using the **CIFAR-10 dataset**.  

GitHub: [ai-portfolio â€“ silentfortin](https://github.com/silentfortin/ai-portfolio/)  

