{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/silentfortin/ai-portfolio/blob/main/06-dl-pytorch-food/food_image_classification_optimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pEEKwXATuOLP"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries for data handling, visualization, and deep learning.\n",
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "import io\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from collections import Counter\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms, models\n",
        "from torchvision.datasets import ImageFolder\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed for reproducibility of results\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "CFeyFXlQPAB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose device: GPU if available, otherwise CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using this device: {device}')"
      ],
      "metadata": {
        "id": "LVwK1-gkzAFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utility function(s)"
      ],
      "metadata": {
        "id": "H73y5Hs1RYUj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_images_per_class(folder_path):\n",
        "    \"\"\"\n",
        "    Count the number of images in each class subfolder of the given directory.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    folder_path : str\n",
        "        Path to the parent directory containing one subdirectory per class.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    dict\n",
        "        A dictionary mapping class names to the number of images in each subfolder.\n",
        "    \"\"\"\n",
        "    counts = {}\n",
        "    for class_name in os.listdir(folder_path):\n",
        "        class_folder = os.path.join(folder_path, class_name)\n",
        "        if os.path.isdir(class_folder):\n",
        "            counts[class_name] = len(os.listdir(class_folder))\n",
        "    return counts"
      ],
      "metadata": {
        "id": "wNC7-QRT7eG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, dataloader):\n",
        "  \"\"\"\n",
        "  Evaluates a PyTorch model on a given validation dataset.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  model : torch.nn.Module\n",
        "      The model to evaluate.\n",
        "  dataloader : torch.utils.data.DataLoader\n",
        "      DataLoader yielding batches from the validation set.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  val_loss : float\n",
        "      Average validation loss over all batches.\n",
        "  val_accuracy : float\n",
        "      Classification accuracy on the validation set.\n",
        "  \"\"\"\n",
        "  model.eval()\n",
        "  val_loss, correct, total = 0, 0, 0\n",
        "  with torch.no_grad():\n",
        "    for images, labels in dataloader:\n",
        "      images, labels = images.to(device), labels.to(device)\n",
        "      outputs = model(images)\n",
        "\n",
        "      loss = criterion(outputs, labels)\n",
        "      val_loss += loss.item()\n",
        "      _, predicted = torch.max(outputs, 1)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "  return val_loss/len(dataloader), correct/total"
      ],
      "metadata": {
        "id": "uwnEIlHJTzrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_on_test(model, test_loader):\n",
        "  \"\"\"\n",
        "  Runs model inference on the test set and collects all true and predicted labels.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  model : torch.nn.Module\n",
        "      Trained model for evaluation.\n",
        "  test_loader : torch.utils.data.DataLoader\n",
        "      DataLoader for the test dataset.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  y_true : list of int\n",
        "      Ground truth class indices.\n",
        "  y_pred : list of int\n",
        "      Predicted class indices by the model.\n",
        "  \"\"\"\n",
        "  y_true, y_pred = [], []\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "      images, labels = images.to(device), labels.to(device)\n",
        "      outputs = model(images)\n",
        "      _, predicted = torch.max(outputs, 1)\n",
        "      y_true.extend(labels.cpu().numpy())\n",
        "      y_pred.extend(predicted.cpu().numpy())\n",
        "  return y_true, y_pred"
      ],
      "metadata": {
        "id": "MrXajDaqR6uQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_optimizer(model, lr, weight_decay=1e-4, t_max=10):\n",
        "    \"\"\"\n",
        "    Creates an AdamW optimizer and CosineAnnealingLR scheduler for model training.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model : torch.nn.Module\n",
        "        The model with parameters to be optimized.\n",
        "    lr : float\n",
        "        Initial learning rate.\n",
        "    weight_decay : float, optional\n",
        "        L2 regularization coefficient. Default is 1e-4.\n",
        "    t_max : int, optional\n",
        "        Number of iterations for cosine annealing scheduler. Default is 10.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    optimizer : torch.optim.Optimizer\n",
        "        Configured AdamW optimizer.\n",
        "    scheduler : torch.optim.lr_scheduler._LRScheduler\n",
        "        CosineAnnealingLR scheduler.\n",
        "    \"\"\"\n",
        "    trainable_params = filter(lambda p: p.requires_grad, model.parameters())\n",
        "    optimizer = torch.optim.AdamW(trainable_params, lr=lr, weight_decay=weight_decay)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=t_max)\n",
        "    return optimizer, scheduler"
      ],
      "metadata": {
        "id": "nXFLadKNTtjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_training_logs(train_losses, val_losses, train_accs, val_accs, filename):\n",
        "    \"\"\"\n",
        "    Saves training and validation loss and accuracy logs to a JSON file.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    train_losses : list of float\n",
        "        List of training loss values for each epoch.\n",
        "    val_losses : list of float\n",
        "        List of validation loss values for each epoch.\n",
        "    train_accs : list of float\n",
        "        List of training accuracy values for each epoch.\n",
        "    val_accs : list of float\n",
        "        List of validation accuracy values for each epoch.\n",
        "    filename : str\n",
        "        Path to the JSON file where logs will be saved.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    None\n",
        "    \"\"\"\n",
        "    logs = {\n",
        "        \"train_losses\": train_losses,\n",
        "        \"val_losses\": val_losses,\n",
        "        \"train_accs\": train_accs,\n",
        "        \"val_accs\": val_accs\n",
        "    }\n",
        "    with open(filename, \"w\") as f:\n",
        "        json.dump(logs, f)\n",
        "    print(f\"Logs saved to {filename}\")"
      ],
      "metadata": {
        "id": "hacT6M2Lqwmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_training_logs(filename):\n",
        "    \"\"\"\n",
        "    Loads training and validation loss and accuracy logs from a JSON file.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    filename : str\n",
        "        Path to the JSON file containing the logs.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    train_losses : list of float\n",
        "        List of training loss values per epoch.\n",
        "    val_losses : list of float\n",
        "        List of validation loss values per epoch.\n",
        "    train_accs : list of float\n",
        "        List of training accuracy values per epoch.\n",
        "    val_accs : list of float\n",
        "        List of validation accuracy values per epoch.\n",
        "    \"\"\"\n",
        "    with open(filename, \"r\") as f:\n",
        "        logs = json.load(f)\n",
        "    print(f\"Logs loaded from {filename}\")\n",
        "    return (logs[\"train_losses\"], logs[\"val_losses\"],\n",
        "            logs[\"train_accs\"], logs[\"val_accs\"])\n"
      ],
      "metadata": {
        "id": "B-XeAZoRvxLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_results(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Prints classification results including accuracy, macro F1-score, and a classification report.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  y_true : list or numpy.ndarray\n",
        "      Ground truth class labels.\n",
        "  y_pred : list or numpy.ndarray\n",
        "      Predicted class labels.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  None\n",
        "  \"\"\"\n",
        "  # Accuracy\n",
        "  accuracy = accuracy_score(y_true, y_pred)\n",
        "  print(f'Test Accuracy: {accuracy*100:.2f}%')\n",
        "\n",
        "  # F1-score macro\n",
        "  f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
        "  print(f\"Macro F1-score: {f1:.4f}\")\n",
        "\n",
        "  # Classification report\n",
        "  print(\"Classification Report:\")\n",
        "  print(classification_report(y_true, y_pred, target_names=class_names))"
      ],
      "metadata": {
        "id": "yb2TTBmSRbvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_curves(train_losses, val_losses, train_accs, val_accs, title=\"Training Curves\"):\n",
        "    \"\"\"\n",
        "    Plots training and validation loss and accuracy curves over epochs.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    train_losses : list of float\n",
        "        Training loss at each epoch.\n",
        "    val_losses : list of float\n",
        "        Validation loss at each epoch.\n",
        "    train_accs : list of float\n",
        "        Training accuracy at each epoch.\n",
        "    val_accs : list of float\n",
        "        Validation accuracy at each epoch.\n",
        "    title : str, optional\n",
        "        Overall plot title.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    None\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(12,5))\n",
        "\n",
        "    # Loss\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.plot(train_losses, label=\"Train Loss\")\n",
        "    plt.plot(val_losses, label=\"Val Loss\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Loss over epochs\")\n",
        "    plt.legend()\n",
        "\n",
        "    # Accuracy\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.plot(train_accs, label=\"Train Acc\")\n",
        "    plt.plot(val_accs, label=\"Val Acc\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.title(\"Accuracy over epochs\")\n",
        "    plt.legend()\n",
        "\n",
        "    plt.suptitle(title)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "iki-yYhH8m7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download and unzip the dataset from the given URL\n",
        "url = \"https://proai-datasets.s3.eu-west-3.amazonaws.com/dataset_food_classification.zip\"\n",
        "\n",
        "response = requests.get(url)\n",
        "response.raise_for_status()\n",
        "\n",
        "zip_file = zipfile.ZipFile(io.BytesIO(response.content))\n",
        "\n",
        "zip_file.extractall(\"/content/\")\n"
      ],
      "metadata": {
        "id": "mnGlWLwguljU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Wrapper for using Albumentations with PyTorch Datasets\n",
        "class AlbumentationsTransform:\n",
        "    def __init__(self, transform):\n",
        "        self.transform = transform\n",
        "\n",
        "    def __call__(self, img):\n",
        "        # Convert PIL -> NumPy array\n",
        "        img = np.array(img)\n",
        "        return self.transform(image=img)[\"image\"]"
      ],
      "metadata": {
        "id": "LS-i3m-0_D-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define data augmentation pipeline for training images\n",
        "train_transform = A.Compose([\n",
        "    A.Resize(256, 256),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.VerticalFlip(p=0.5),\n",
        "    A.RandomRotate90(p=0.5),\n",
        "    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1, rotate_limit=15, p=0.5),\n",
        "    A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1, p=0.5),\n",
        "    A.RandomBrightnessContrast(p=0.5),\n",
        "    A.GaussianBlur(blur_limit=(3,5), p=0.3),\n",
        "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "# Augmentation pipeline for validation/test (no random operations)\n",
        "val_test_transform = A.Compose([\n",
        "    A.Resize(256, 256),\n",
        "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "    ToTensorV2()\n",
        "])"
      ],
      "metadata": {
        "id": "lZfPTHpUzQrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare datasets with class folders; apply appropriate transforms\n",
        "train_dataset = ImageFolder(root='/content/dataset/train', transform=AlbumentationsTransform(train_transform))\n",
        "val_dataset = ImageFolder(root='/content/dataset/val', transform=AlbumentationsTransform(train_transform))\n",
        "test_dataset = ImageFolder(root='/content/dataset/test', transform=AlbumentationsTransform(val_test_transform))\n",
        "\n",
        "# Create DataLoaders to efficiently batch and shuffle data for training\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "# Get the class names list\n",
        "class_names = train_loader.dataset.classes"
      ],
      "metadata": {
        "id": "LXlcvMc4wGlB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print dataset statistics\n",
        "print(f'Train samples: {len(train_dataset)}')\n",
        "print(f'Valid samples: {len(val_dataset)}')\n",
        "print(f'Test samples: {len(test_dataset)}')\n",
        "\n",
        "train_counts = count_images_per_class('/content/dataset/train')\n",
        "val_counts = count_images_per_class('/content/dataset/val')\n",
        "test_counts = count_images_per_class('/content/dataset/test')\n",
        "\n",
        "print(\"Train class distribution:\", train_counts)\n",
        "print(\"Validation class distribution:\", val_counts)\n",
        "print(\"Test class distribution:\", test_counts)"
      ],
      "metadata": {
        "id": "RJTWJbPK8bsn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare tensors for image denormalization (revert normalized images to viewable format)\n",
        "mean = torch.tensor([0.485, 0.456, 0.406]).view(3,1,1)\n",
        "std = torch.tensor([0.229, 0.224, 0.225]).view(3,1,1)\n",
        "\n",
        "def denormalize(img):\n",
        "    return img * std + mean\n",
        "\n",
        "# Visualize examplse images from training set\n",
        "examples = iter(train_loader)\n",
        "images, labels = next(examples)\n",
        "\n",
        "plt.figure(figsize=(8,3))\n",
        "\n",
        "for i in range(4):\n",
        "    plt.subplot(1,4,i+1)\n",
        "    img = denormalize(images[i])\n",
        "    img = img.permute(1, 2, 0).clamp(0,1)\n",
        "    plt.imshow(img)\n",
        "    plt.title(str(labels[i].item()))\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5OERZGK_9lnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning Model"
      ],
      "metadata": {
        "id": "U01RyHIpT9T5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Early stopping utility to avoid overfitting (stop if no val improvement for X epochs)\n",
        "class EarlyStopping:\n",
        "  def __init__(self, patience=5):\n",
        "      self.patience = patience\n",
        "      self.counter = 0\n",
        "      self.best_loss = None\n",
        "      self.early_stop = False\n",
        "\n",
        "  def __call__(self, val_loss):\n",
        "    if self.best_loss is None or val_loss < self.best_loss:\n",
        "      self.best_loss = val_loss\n",
        "      self.counter = 0\n",
        "    else:\n",
        "      self.counter += 1\n",
        "      if self.counter == self.patience:\n",
        "        self.early_stop = True"
      ],
      "metadata": {
        "id": "OfxUlEaHfNxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create ResNet50 baseline model for 14 food classes\n",
        "num_classes = 14\n",
        "baseline_model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
        "# Freeze all parameters to use as feature extractor\n",
        "for param in baseline_model.parameters():\n",
        "  param.requires_grad = False\n",
        "baseline_model.fc = nn.Linear(baseline_model.fc.in_features, num_classes)\n",
        "baseline_model = baseline_model.to(device)"
      ],
      "metadata": {
        "id": "i_ujEJdNUAt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training setup"
      ],
      "metadata": {
        "id": "kMAqZqYTXyFr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define loss function and optimizer/scheduler for baseline model training\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# AdamW\n",
        "optimizer = optim.AdamW(baseline_model.fc.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "# CosineAnnealingLR\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)"
      ],
      "metadata": {
        "id": "sDlK01kfXzuJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and validate"
      ],
      "metadata": {
        "id": "AGlYra2iy1QF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set number of epochs\n",
        "epochs = 35"
      ],
      "metadata": {
        "id": "hY8b-Oo_fX0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "early_stopping = EarlyStopping(patience=3)\n",
        "\n",
        "# Initialize logs for loss/accuracy\n",
        "baseline_train_losses, baseline_val_losses = [], []\n",
        "baseline_train_accs, baseline_val_accs = [], []\n",
        "\n",
        "# Training loop for baseline model\n",
        "for epoch in range(epochs):\n",
        "    baseline_model.train()\n",
        "    correct_train, total_train = 0, 0\n",
        "    running_loss = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = baseline_model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Track training accuracy\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total_train += labels.size(0)\n",
        "        correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "    train_acc = correct_train / total_train\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "\n",
        "    scheduler.step()\n",
        "    val_loss, val_acc = evaluate(baseline_model, val_loader)\n",
        "\n",
        "    # Logging\n",
        "    baseline_train_losses.append(train_loss)\n",
        "    baseline_val_losses.append(val_loss)\n",
        "    baseline_train_accs.append(train_acc)\n",
        "    baseline_val_accs.append(val_acc)\n",
        "\n",
        "    print(f\"[Epoch {epoch+1}] Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
        "          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "    early_stopping(val_loss)\n",
        "    if early_stopping.early_stop:\n",
        "        print(\"Early stopping triggered.\")\n",
        "        break"
      ],
      "metadata": {
        "id": "cbQWzCVqfYyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save baseline trained model parameters\n",
        "torch.save(baseline_model.state_dict(), 'baseline_model.pth')\n",
        "print(\"Baseline model saved\")"
      ],
      "metadata": {
        "id": "i276p_sKXGV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving training logs\n",
        "save_training_logs(baseline_train_losses, baseline_val_losses,\n",
        "                   baseline_train_accs, baseline_val_accs,\n",
        "                   \"baseline_logs.json\")"
      ],
      "metadata": {
        "id": "FCp7AvVdq-b3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the baseline model\n",
        "# baseline_model.load_state_dict(torch.load('baseline_model.pth'))\n",
        "\n",
        "# moving to gpu\n",
        "# baseline_model.to(device)"
      ],
      "metadata": {
        "id": "_R99Qn36pUsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training curves for baseline model\n",
        "train_losses, val_losses, train_accs, val_accs = load_training_logs(\"baseline_logs.json\")\n",
        "plot_curves(train_losses, val_losses, train_accs, val_accs, title=\"Baseline Training Curves\")"
      ],
      "metadata": {
        "id": "eAKEHb_Jpzse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate baseline model on test set\n",
        "baseline_model.load_state_dict(torch.load(\"baseline_model.pth\"))\n",
        "baseline_model.to(device)\n",
        "y_true_base, y_pred_base = evaluate_on_test(baseline_model, test_loader)\n",
        "print(\"Baseline Results\")\n",
        "print_results(y_true_base, y_pred_base)\n"
      ],
      "metadata": {
        "id": "ja96_qjsU7xl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Redefine model for fine tuning (reset and unfreeze)\n",
        "fine_tuned_model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
        "num_ftrs = fine_tuned_model.fc.in_features\n",
        "fine_tuned_model.fc = nn.Linear(num_ftrs, 14)  # 14 classi, stesso numero usato nel training"
      ],
      "metadata": {
        "id": "GbtBir9rmA2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the trained one\n",
        "# fine_tuned_model.load_state_dict(torch.load('baseline_model.pth'))\n",
        "\n",
        "# moving to gpu\n",
        "fine_tuned_model.to(device)"
      ],
      "metadata": {
        "id": "4QrT49H2xpWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine tuning"
      ],
      "metadata": {
        "id": "1Lfk6ClMeFkZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(patience=3)\n",
        "\n",
        "# Logs for fine-tuning training\n",
        "finetune_train_losses, finetune_val_losses = [], []\n",
        "finetune_train_accs, finetune_val_accs = [], []\n",
        "\n",
        "# Training loop for gradual unfreezing/fine tuning\n",
        "for epoch in range(epochs):\n",
        "    # Gradually unfreeze more layers and change learning rate as training progresses\n",
        "    if epoch == 0:\n",
        "        for name, param in fine_tuned_model.named_parameters():\n",
        "            param.requires_grad = (\"fc\" in name)\n",
        "        optimizer, scheduler = set_optimizer(fine_tuned_model, lr=1e-3)\n",
        "\n",
        "    elif epoch == 5:\n",
        "        for name, param in fine_tuned_model.named_parameters():\n",
        "            param.requires_grad = (\"fc\" in name or \"layer4\" in name)\n",
        "        optimizer, scheduler = set_optimizer(fine_tuned_model, lr=1e-4)\n",
        "\n",
        "    elif epoch == 10:\n",
        "        for name, param in fine_tuned_model.named_parameters():\n",
        "            param.requires_grad = (\"fc\" in name or \"layer4\" in name or \"layer3\" in name)\n",
        "        optimizer, scheduler = set_optimizer(fine_tuned_model, lr=1e-5)\n",
        "\n",
        "    # Training phase for fine-tuned model\n",
        "    fine_tuned_model.train()\n",
        "    running_loss, correct_train, total_train = 0, 0, 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = fine_tuned_model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total_train += labels.size(0)\n",
        "        correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "    train_acc = correct_train / total_train\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "\n",
        "    scheduler.step()\n",
        "    val_loss, val_acc = evaluate(fine_tuned_model, val_loader)\n",
        "\n",
        "    # Logging\n",
        "    finetune_train_losses.append(train_loss)\n",
        "    finetune_val_losses.append(val_loss)\n",
        "    finetune_train_accs.append(train_acc)\n",
        "    finetune_val_accs.append(val_acc)\n",
        "\n",
        "    print(f\"[Epoch {epoch+1}] Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
        "          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "    # Save best model for lowest val loss\n",
        "    if early_stopping.best_loss is None or val_loss < early_stopping.best_loss:\n",
        "        torch.save(fine_tuned_model.state_dict(), \"best_finetuned_model.pth\")\n",
        "        print(\"Best fine-tuned model saved\")\n",
        "\n",
        "    early_stopping(val_loss)\n",
        "    if early_stopping.early_stop:\n",
        "        print(\"Early stopping triggered\")\n",
        "        break"
      ],
      "metadata": {
        "id": "y0DSjpVveGew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving training logs for fined-tuned model\n",
        "save_training_logs(finetune_train_losses, finetune_val_losses,\n",
        "                   finetune_train_accs, finetune_val_accs,\n",
        "                   \"finetune_logs.json\")"
      ],
      "metadata": {
        "id": "pGOCMBvwrTFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load best fine-tuned parameters before final evaluation\n",
        "fine_tuned_model.load_state_dict(torch.load(\"best_finetuned_model.pth\"))\n",
        "fine_tuned_model.to(device)"
      ],
      "metadata": {
        "id": "sjnGQAoW8Ey1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot curves for fine-tuned training\n",
        "train_losses, val_losses, train_accs, val_accs = load_training_logs(\"finetune_logs.json\")\n",
        "plot_curves(train_losses, val_losses, train_accs, val_accs, title=\"Baseline Training Curves\")"
      ],
      "metadata": {
        "id": "x6GcXs9crU0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_true, y_pred = evaluate_on_test(fine_tuned_model, test_loader)"
      ],
      "metadata": {
        "id": "xEjBIiB6qSih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print final test results after fine tuning\n",
        "print_results(y_true, y_pred)"
      ],
      "metadata": {
        "id": "AtHF4UcLcek3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix for error analysis of fine-tuned model\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap=\"Blues\", cbar=False,\n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "\n",
        "plt.xticks(rotation=45)\n",
        "plt.yticks(rotation=0)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8dl15Z-0Awps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show predictions vs. truth for six test images (for visual assessment)\n",
        "examples = iter(test_loader)\n",
        "images, labels = next(examples)\n",
        "images, labels = images.to(device), labels.to(device)\n",
        "outputs = fine_tuned_model(images)\n",
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "for i in range(min(6, len(images))):\n",
        "    plt.subplot(1, 6, i+1)\n",
        "    img = denormalize(images[i].cpu())\n",
        "    img = img.permute(1, 2, 0).clamp(0, 1)\n",
        "    plt.imshow(img)\n",
        "    plt.title(f\"P: {class_names[predicted[i].cpu().item()]}\\nT: {class_names[labels[i].cpu().item()]}\")\n",
        "    plt.axis(\"off\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7h9EGY2r_ZF9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}